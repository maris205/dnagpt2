{
  "best_metric": 0.91875,
  "best_model_checkpoint": "./gpt2_lora_text_classification/checkpoint-46620",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 66600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07507507507507508,
      "grad_norm": 0.6601091623306274,
      "learning_rate": 1.9850750750750752e-05,
      "loss": 0.2791,
      "step": 500
    },
    {
      "epoch": 0.15015015015015015,
      "grad_norm": 15.015149116516113,
      "learning_rate": 1.9700600600600603e-05,
      "loss": 0.2868,
      "step": 1000
    },
    {
      "epoch": 0.22522522522522523,
      "grad_norm": 6.76954984664917,
      "learning_rate": 1.955045045045045e-05,
      "loss": 0.2775,
      "step": 1500
    },
    {
      "epoch": 0.3003003003003003,
      "grad_norm": 15.123693466186523,
      "learning_rate": 1.94003003003003e-05,
      "loss": 0.2902,
      "step": 2000
    },
    {
      "epoch": 0.37537537537537535,
      "grad_norm": 14.731389045715332,
      "learning_rate": 1.925015015015015e-05,
      "loss": 0.2755,
      "step": 2500
    },
    {
      "epoch": 0.45045045045045046,
      "grad_norm": 6.209009647369385,
      "learning_rate": 1.91e-05,
      "loss": 0.296,
      "step": 3000
    },
    {
      "epoch": 0.5255255255255256,
      "grad_norm": 36.11541748046875,
      "learning_rate": 1.894984984984985e-05,
      "loss": 0.2902,
      "step": 3500
    },
    {
      "epoch": 0.6006006006006006,
      "grad_norm": 13.450925827026367,
      "learning_rate": 1.87996996996997e-05,
      "loss": 0.26,
      "step": 4000
    },
    {
      "epoch": 0.6756756756756757,
      "grad_norm": 19.150455474853516,
      "learning_rate": 1.864984984984985e-05,
      "loss": 0.2725,
      "step": 4500
    },
    {
      "epoch": 0.7507507507507507,
      "grad_norm": 1.4110784530639648,
      "learning_rate": 1.84996996996997e-05,
      "loss": 0.2842,
      "step": 5000
    },
    {
      "epoch": 0.8258258258258259,
      "grad_norm": 1.0682216882705688,
      "learning_rate": 1.834954954954955e-05,
      "loss": 0.2743,
      "step": 5500
    },
    {
      "epoch": 0.9009009009009009,
      "grad_norm": 0.35149845480918884,
      "learning_rate": 1.8199699699699703e-05,
      "loss": 0.2616,
      "step": 6000
    },
    {
      "epoch": 0.975975975975976,
      "grad_norm": 12.264653205871582,
      "learning_rate": 1.8049549549549553e-05,
      "loss": 0.2683,
      "step": 6500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9097972972972973,
      "eval_f1": 0.9093378607809848,
      "eval_loss": 0.3078426420688629,
      "eval_precision": 0.9168093118794933,
      "eval_recall": 0.901987201077804,
      "eval_runtime": 6.9148,
      "eval_samples_per_second": 856.136,
      "eval_steps_per_second": 107.017,
      "step": 6660
    },
    {
      "epoch": 1.0510510510510511,
      "grad_norm": 0.6039217114448547,
      "learning_rate": 1.7899399399399403e-05,
      "loss": 0.2609,
      "step": 7000
    },
    {
      "epoch": 1.1261261261261262,
      "grad_norm": 15.304805755615234,
      "learning_rate": 1.774924924924925e-05,
      "loss": 0.2652,
      "step": 7500
    },
    {
      "epoch": 1.2012012012012012,
      "grad_norm": 1.7410695552825928,
      "learning_rate": 1.7599399399399403e-05,
      "loss": 0.2701,
      "step": 8000
    },
    {
      "epoch": 1.2762762762762763,
      "grad_norm": 0.29760709404945374,
      "learning_rate": 1.7449249249249253e-05,
      "loss": 0.2592,
      "step": 8500
    },
    {
      "epoch": 1.3513513513513513,
      "grad_norm": 9.87925910949707,
      "learning_rate": 1.72990990990991e-05,
      "loss": 0.2571,
      "step": 9000
    },
    {
      "epoch": 1.4264264264264264,
      "grad_norm": 3.006570339202881,
      "learning_rate": 1.714894894894895e-05,
      "loss": 0.2793,
      "step": 9500
    },
    {
      "epoch": 1.5015015015015014,
      "grad_norm": 15.687701225280762,
      "learning_rate": 1.69987987987988e-05,
      "loss": 0.2658,
      "step": 10000
    },
    {
      "epoch": 1.5765765765765765,
      "grad_norm": 14.420040130615234,
      "learning_rate": 1.684894894894895e-05,
      "loss": 0.2525,
      "step": 10500
    },
    {
      "epoch": 1.6516516516516515,
      "grad_norm": 5.118183135986328,
      "learning_rate": 1.66987987987988e-05,
      "loss": 0.2773,
      "step": 11000
    },
    {
      "epoch": 1.7267267267267268,
      "grad_norm": 4.803476333618164,
      "learning_rate": 1.654864864864865e-05,
      "loss": 0.2533,
      "step": 11500
    },
    {
      "epoch": 1.8018018018018018,
      "grad_norm": 12.475725173950195,
      "learning_rate": 1.63984984984985e-05,
      "loss": 0.2778,
      "step": 12000
    },
    {
      "epoch": 1.8768768768768769,
      "grad_norm": 0.4601811170578003,
      "learning_rate": 1.624834834834835e-05,
      "loss": 0.2595,
      "step": 12500
    },
    {
      "epoch": 1.951951951951952,
      "grad_norm": 9.139686584472656,
      "learning_rate": 1.60981981981982e-05,
      "loss": 0.2874,
      "step": 13000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9135135135135135,
      "eval_f1": 0.9150912106135987,
      "eval_loss": 0.27880367636680603,
      "eval_precision": 0.9013394315583143,
      "eval_recall": 0.9292691141798586,
      "eval_runtime": 6.9239,
      "eval_samples_per_second": 855.011,
      "eval_steps_per_second": 106.876,
      "step": 13320
    },
    {
      "epoch": 2.027027027027027,
      "grad_norm": 6.4723801612854,
      "learning_rate": 1.594804804804805e-05,
      "loss": 0.2424,
      "step": 13500
    },
    {
      "epoch": 2.1021021021021022,
      "grad_norm": 2.6300477981567383,
      "learning_rate": 1.57978978978979e-05,
      "loss": 0.253,
      "step": 14000
    },
    {
      "epoch": 2.1771771771771773,
      "grad_norm": 0.37813109159469604,
      "learning_rate": 1.564804804804805e-05,
      "loss": 0.2745,
      "step": 14500
    },
    {
      "epoch": 2.2522522522522523,
      "grad_norm": 8.724522590637207,
      "learning_rate": 1.54981981981982e-05,
      "loss": 0.2575,
      "step": 15000
    },
    {
      "epoch": 2.3273273273273274,
      "grad_norm": 16.1109619140625,
      "learning_rate": 1.534804804804805e-05,
      "loss": 0.2579,
      "step": 15500
    },
    {
      "epoch": 2.4024024024024024,
      "grad_norm": 9.96057415008545,
      "learning_rate": 1.51978978978979e-05,
      "loss": 0.248,
      "step": 16000
    },
    {
      "epoch": 2.4774774774774775,
      "grad_norm": 1.349557876586914,
      "learning_rate": 1.504774774774775e-05,
      "loss": 0.2422,
      "step": 16500
    },
    {
      "epoch": 2.5525525525525525,
      "grad_norm": 0.23730000853538513,
      "learning_rate": 1.48975975975976e-05,
      "loss": 0.2905,
      "step": 17000
    },
    {
      "epoch": 2.6276276276276276,
      "grad_norm": 13.847168922424316,
      "learning_rate": 1.474774774774775e-05,
      "loss": 0.2584,
      "step": 17500
    },
    {
      "epoch": 2.7027027027027026,
      "grad_norm": 8.907866477966309,
      "learning_rate": 1.45975975975976e-05,
      "loss": 0.2855,
      "step": 18000
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 9.752605438232422,
      "learning_rate": 1.4447447447447448e-05,
      "loss": 0.239,
      "step": 18500
    },
    {
      "epoch": 2.8528528528528527,
      "grad_norm": 16.184972763061523,
      "learning_rate": 1.4297297297297299e-05,
      "loss": 0.2749,
      "step": 19000
    },
    {
      "epoch": 2.9279279279279278,
      "grad_norm": 17.949094772338867,
      "learning_rate": 1.4147147147147149e-05,
      "loss": 0.2828,
      "step": 19500
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.914527027027027,
      "eval_f1": 0.9149579831932773,
      "eval_loss": 0.29122158885002136,
      "eval_precision": 0.9131164038913117,
      "eval_recall": 0.9168070057258336,
      "eval_runtime": 6.8853,
      "eval_samples_per_second": 859.802,
      "eval_steps_per_second": 107.475,
      "step": 19980
    },
    {
      "epoch": 3.003003003003003,
      "grad_norm": 2.0944182872772217,
      "learning_rate": 1.3996996996996999e-05,
      "loss": 0.2426,
      "step": 20000
    },
    {
      "epoch": 3.078078078078078,
      "grad_norm": 24.096668243408203,
      "learning_rate": 1.3847147147147148e-05,
      "loss": 0.2566,
      "step": 20500
    },
    {
      "epoch": 3.153153153153153,
      "grad_norm": 22.673879623413086,
      "learning_rate": 1.3696996996996998e-05,
      "loss": 0.2579,
      "step": 21000
    },
    {
      "epoch": 3.2282282282282284,
      "grad_norm": 14.733776092529297,
      "learning_rate": 1.3546846846846849e-05,
      "loss": 0.2613,
      "step": 21500
    },
    {
      "epoch": 3.3033033033033035,
      "grad_norm": 3.1102752685546875,
      "learning_rate": 1.3396696696696699e-05,
      "loss": 0.2571,
      "step": 22000
    },
    {
      "epoch": 3.3783783783783785,
      "grad_norm": 12.633967399597168,
      "learning_rate": 1.3246546546546547e-05,
      "loss": 0.2528,
      "step": 22500
    },
    {
      "epoch": 3.4534534534534536,
      "grad_norm": 13.392036437988281,
      "learning_rate": 1.3096696696696698e-05,
      "loss": 0.2507,
      "step": 23000
    },
    {
      "epoch": 3.5285285285285286,
      "grad_norm": 17.981300354003906,
      "learning_rate": 1.2946546546546549e-05,
      "loss": 0.2486,
      "step": 23500
    },
    {
      "epoch": 3.6036036036036037,
      "grad_norm": 12.166417121887207,
      "learning_rate": 1.2796396396396397e-05,
      "loss": 0.2392,
      "step": 24000
    },
    {
      "epoch": 3.6786786786786787,
      "grad_norm": 1.0378447771072388,
      "learning_rate": 1.2646246246246247e-05,
      "loss": 0.2799,
      "step": 24500
    },
    {
      "epoch": 3.7537537537537538,
      "grad_norm": 18.767398834228516,
      "learning_rate": 1.2496096096096097e-05,
      "loss": 0.2654,
      "step": 25000
    },
    {
      "epoch": 3.828828828828829,
      "grad_norm": 36.50725173950195,
      "learning_rate": 1.2346246246246247e-05,
      "loss": 0.245,
      "step": 25500
    },
    {
      "epoch": 3.903903903903904,
      "grad_norm": 1.3716295957565308,
      "learning_rate": 1.2196096096096097e-05,
      "loss": 0.2468,
      "step": 26000
    },
    {
      "epoch": 3.978978978978979,
      "grad_norm": 8.420230865478516,
      "learning_rate": 1.2045945945945947e-05,
      "loss": 0.2552,
      "step": 26500
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9163851351351351,
      "eval_f1": 0.9187058630316965,
      "eval_loss": 0.2815721333026886,
      "eval_precision": 0.896474358974359,
      "eval_recall": 0.9420680363758841,
      "eval_runtime": 6.8819,
      "eval_samples_per_second": 860.228,
      "eval_steps_per_second": 107.529,
      "step": 26640
    },
    {
      "epoch": 4.054054054054054,
      "grad_norm": 12.154544830322266,
      "learning_rate": 1.1895795795795797e-05,
      "loss": 0.2599,
      "step": 27000
    },
    {
      "epoch": 4.129129129129129,
      "grad_norm": 18.989110946655273,
      "learning_rate": 1.1745645645645648e-05,
      "loss": 0.2299,
      "step": 27500
    },
    {
      "epoch": 4.2042042042042045,
      "grad_norm": 15.256402969360352,
      "learning_rate": 1.1595495495495496e-05,
      "loss": 0.2793,
      "step": 28000
    },
    {
      "epoch": 4.2792792792792795,
      "grad_norm": 0.3791729211807251,
      "learning_rate": 1.1445645645645647e-05,
      "loss": 0.2362,
      "step": 28500
    },
    {
      "epoch": 4.354354354354355,
      "grad_norm": 0.3302192986011505,
      "learning_rate": 1.1295495495495497e-05,
      "loss": 0.2487,
      "step": 29000
    },
    {
      "epoch": 4.42942942942943,
      "grad_norm": 0.19345639646053314,
      "learning_rate": 1.1145345345345346e-05,
      "loss": 0.2693,
      "step": 29500
    },
    {
      "epoch": 4.504504504504505,
      "grad_norm": 0.5276665091514587,
      "learning_rate": 1.0995195195195196e-05,
      "loss": 0.2515,
      "step": 30000
    },
    {
      "epoch": 4.57957957957958,
      "grad_norm": 17.693134307861328,
      "learning_rate": 1.0845045045045046e-05,
      "loss": 0.2398,
      "step": 30500
    },
    {
      "epoch": 4.654654654654655,
      "grad_norm": 4.102345943450928,
      "learning_rate": 1.0695195195195196e-05,
      "loss": 0.2534,
      "step": 31000
    },
    {
      "epoch": 4.72972972972973,
      "grad_norm": 14.490029335021973,
      "learning_rate": 1.0545045045045046e-05,
      "loss": 0.2591,
      "step": 31500
    },
    {
      "epoch": 4.804804804804805,
      "grad_norm": 0.18800705671310425,
      "learning_rate": 1.0394894894894896e-05,
      "loss": 0.2433,
      "step": 32000
    },
    {
      "epoch": 4.87987987987988,
      "grad_norm": 1.4547662734985352,
      "learning_rate": 1.0244744744744746e-05,
      "loss": 0.2514,
      "step": 32500
    },
    {
      "epoch": 4.954954954954955,
      "grad_norm": 23.680500030517578,
      "learning_rate": 1.0094894894894895e-05,
      "loss": 0.252,
      "step": 33000
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.914527027027027,
      "eval_f1": 0.9149579831932773,
      "eval_loss": 0.27195000648498535,
      "eval_precision": 0.9131164038913117,
      "eval_recall": 0.9168070057258336,
      "eval_runtime": 6.9368,
      "eval_samples_per_second": 853.416,
      "eval_steps_per_second": 106.677,
      "step": 33300
    },
    {
      "epoch": 5.03003003003003,
      "grad_norm": 0.7097603678703308,
      "learning_rate": 9.944744744744746e-06,
      "loss": 0.2542,
      "step": 33500
    },
    {
      "epoch": 5.105105105105105,
      "grad_norm": 9.578977584838867,
      "learning_rate": 9.794594594594596e-06,
      "loss": 0.2614,
      "step": 34000
    },
    {
      "epoch": 5.18018018018018,
      "grad_norm": 55.42725372314453,
      "learning_rate": 9.644444444444444e-06,
      "loss": 0.2489,
      "step": 34500
    },
    {
      "epoch": 5.255255255255255,
      "grad_norm": 9.72994613647461,
      "learning_rate": 9.494594594594595e-06,
      "loss": 0.2535,
      "step": 35000
    },
    {
      "epoch": 5.33033033033033,
      "grad_norm": 9.581122398376465,
      "learning_rate": 9.344444444444446e-06,
      "loss": 0.2594,
      "step": 35500
    },
    {
      "epoch": 5.405405405405405,
      "grad_norm": 8.783069610595703,
      "learning_rate": 9.194294294294294e-06,
      "loss": 0.2499,
      "step": 36000
    },
    {
      "epoch": 5.48048048048048,
      "grad_norm": 21.566892623901367,
      "learning_rate": 9.044144144144144e-06,
      "loss": 0.2391,
      "step": 36500
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 0.5095661878585815,
      "learning_rate": 8.893993993993994e-06,
      "loss": 0.228,
      "step": 37000
    },
    {
      "epoch": 5.63063063063063,
      "grad_norm": 0.5652422904968262,
      "learning_rate": 8.743843843843845e-06,
      "loss": 0.2354,
      "step": 37500
    },
    {
      "epoch": 5.7057057057057055,
      "grad_norm": 22.595531463623047,
      "learning_rate": 8.593693693693695e-06,
      "loss": 0.2313,
      "step": 38000
    },
    {
      "epoch": 5.7807807807807805,
      "grad_norm": 10.465389251708984,
      "learning_rate": 8.443543543543543e-06,
      "loss": 0.2495,
      "step": 38500
    },
    {
      "epoch": 5.8558558558558556,
      "grad_norm": 13.11806583404541,
      "learning_rate": 8.293693693693694e-06,
      "loss": 0.2603,
      "step": 39000
    },
    {
      "epoch": 5.930930930930931,
      "grad_norm": 13.471338272094727,
      "learning_rate": 8.143543543543545e-06,
      "loss": 0.2423,
      "step": 39500
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9163851351351351,
      "eval_f1": 0.9166526351237582,
      "eval_loss": 0.28819864988327026,
      "eval_precision": 0.9164983164983165,
      "eval_recall": 0.9168070057258336,
      "eval_runtime": 6.9985,
      "eval_samples_per_second": 845.898,
      "eval_steps_per_second": 105.737,
      "step": 39960
    },
    {
      "epoch": 6.006006006006006,
      "grad_norm": 1.7739392518997192,
      "learning_rate": 7.993393393393393e-06,
      "loss": 0.247,
      "step": 40000
    },
    {
      "epoch": 6.081081081081081,
      "grad_norm": 7.755850315093994,
      "learning_rate": 7.843243243243243e-06,
      "loss": 0.2288,
      "step": 40500
    },
    {
      "epoch": 6.156156156156156,
      "grad_norm": 4.462266445159912,
      "learning_rate": 7.693093093093093e-06,
      "loss": 0.2566,
      "step": 41000
    },
    {
      "epoch": 6.231231231231231,
      "grad_norm": 14.290399551391602,
      "learning_rate": 7.543243243243244e-06,
      "loss": 0.2559,
      "step": 41500
    },
    {
      "epoch": 6.306306306306306,
      "grad_norm": 14.638737678527832,
      "learning_rate": 7.393093093093093e-06,
      "loss": 0.2237,
      "step": 42000
    },
    {
      "epoch": 6.381381381381382,
      "grad_norm": 0.5656157732009888,
      "learning_rate": 7.242942942942943e-06,
      "loss": 0.2517,
      "step": 42500
    },
    {
      "epoch": 6.456456456456457,
      "grad_norm": 5.043838977813721,
      "learning_rate": 7.092792792792793e-06,
      "loss": 0.2511,
      "step": 43000
    },
    {
      "epoch": 6.531531531531532,
      "grad_norm": 1.055748462677002,
      "learning_rate": 6.942942942942944e-06,
      "loss": 0.2385,
      "step": 43500
    },
    {
      "epoch": 6.606606606606607,
      "grad_norm": 0.2881987392902374,
      "learning_rate": 6.792792792792793e-06,
      "loss": 0.2537,
      "step": 44000
    },
    {
      "epoch": 6.681681681681682,
      "grad_norm": 26.814804077148438,
      "learning_rate": 6.642642642642643e-06,
      "loss": 0.2544,
      "step": 44500
    },
    {
      "epoch": 6.756756756756757,
      "grad_norm": 3.904442548751831,
      "learning_rate": 6.4924924924924924e-06,
      "loss": 0.2322,
      "step": 45000
    },
    {
      "epoch": 6.831831831831832,
      "grad_norm": 0.3679012358188629,
      "learning_rate": 6.342642642642643e-06,
      "loss": 0.2314,
      "step": 45500
    },
    {
      "epoch": 6.906906906906907,
      "grad_norm": 0.13983987271785736,
      "learning_rate": 6.192492492492494e-06,
      "loss": 0.2559,
      "step": 46000
    },
    {
      "epoch": 6.981981981981982,
      "grad_norm": 13.696492195129395,
      "learning_rate": 6.042342342342343e-06,
      "loss": 0.2535,
      "step": 46500
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.91875,
      "eval_f1": 0.9199267521225237,
      "eval_loss": 0.2686730921268463,
      "eval_precision": 0.9094799210006583,
      "eval_recall": 0.9306163691478613,
      "eval_runtime": 6.8805,
      "eval_samples_per_second": 860.409,
      "eval_steps_per_second": 107.551,
      "step": 46620
    },
    {
      "epoch": 7.057057057057057,
      "grad_norm": 1.2342840433120728,
      "learning_rate": 5.892192192192193e-06,
      "loss": 0.2461,
      "step": 47000
    },
    {
      "epoch": 7.132132132132132,
      "grad_norm": 0.11590774357318878,
      "learning_rate": 5.742042042042042e-06,
      "loss": 0.2341,
      "step": 47500
    },
    {
      "epoch": 7.207207207207207,
      "grad_norm": 0.7022895216941833,
      "learning_rate": 5.592192192192193e-06,
      "loss": 0.2617,
      "step": 48000
    },
    {
      "epoch": 7.282282282282282,
      "grad_norm": 0.6305549740791321,
      "learning_rate": 5.442042042042043e-06,
      "loss": 0.2379,
      "step": 48500
    },
    {
      "epoch": 7.357357357357357,
      "grad_norm": 1.8172821998596191,
      "learning_rate": 5.291891891891892e-06,
      "loss": 0.2402,
      "step": 49000
    },
    {
      "epoch": 7.4324324324324325,
      "grad_norm": 5.735633373260498,
      "learning_rate": 5.1417417417417425e-06,
      "loss": 0.2468,
      "step": 49500
    },
    {
      "epoch": 7.5075075075075075,
      "grad_norm": 0.6238136291503906,
      "learning_rate": 4.991891891891893e-06,
      "loss": 0.2284,
      "step": 50000
    },
    {
      "epoch": 7.5825825825825826,
      "grad_norm": 1.6428614854812622,
      "learning_rate": 4.841741741741742e-06,
      "loss": 0.2242,
      "step": 50500
    },
    {
      "epoch": 7.657657657657658,
      "grad_norm": 3.6709420680999756,
      "learning_rate": 4.691591591591592e-06,
      "loss": 0.2313,
      "step": 51000
    },
    {
      "epoch": 7.732732732732733,
      "grad_norm": 1.36298406124115,
      "learning_rate": 4.541441441441442e-06,
      "loss": 0.2372,
      "step": 51500
    },
    {
      "epoch": 7.807807807807808,
      "grad_norm": 1.058044672012329,
      "learning_rate": 4.391291291291292e-06,
      "loss": 0.2267,
      "step": 52000
    },
    {
      "epoch": 7.882882882882883,
      "grad_norm": 9.829523086547852,
      "learning_rate": 4.241441441441442e-06,
      "loss": 0.2695,
      "step": 52500
    },
    {
      "epoch": 7.957957957957958,
      "grad_norm": 6.040225982666016,
      "learning_rate": 4.091591591591592e-06,
      "loss": 0.2359,
      "step": 53000
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9175675675675675,
      "eval_f1": 0.9189099368560983,
      "eval_loss": 0.2778928279876709,
      "eval_precision": 0.9068547064611348,
      "eval_recall": 0.9312899966318626,
      "eval_runtime": 6.9239,
      "eval_samples_per_second": 855.009,
      "eval_steps_per_second": 106.876,
      "step": 53280
    },
    {
      "epoch": 8.033033033033034,
      "grad_norm": 0.8012737035751343,
      "learning_rate": 3.941441441441442e-06,
      "loss": 0.2353,
      "step": 53500
    },
    {
      "epoch": 8.108108108108109,
      "grad_norm": 33.150291442871094,
      "learning_rate": 3.7912912912912915e-06,
      "loss": 0.2411,
      "step": 54000
    },
    {
      "epoch": 8.183183183183184,
      "grad_norm": 0.2979067265987396,
      "learning_rate": 3.6411411411411413e-06,
      "loss": 0.2546,
      "step": 54500
    },
    {
      "epoch": 8.258258258258259,
      "grad_norm": 0.2562500536441803,
      "learning_rate": 3.490990990990991e-06,
      "loss": 0.2189,
      "step": 55000
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.5810413360595703,
      "learning_rate": 3.340840840840841e-06,
      "loss": 0.2389,
      "step": 55500
    },
    {
      "epoch": 8.408408408408409,
      "grad_norm": 15.872923851013184,
      "learning_rate": 3.190690690690691e-06,
      "loss": 0.2512,
      "step": 56000
    },
    {
      "epoch": 8.483483483483484,
      "grad_norm": 1.3113569021224976,
      "learning_rate": 3.040540540540541e-06,
      "loss": 0.2436,
      "step": 56500
    },
    {
      "epoch": 8.558558558558559,
      "grad_norm": 13.303168296813965,
      "learning_rate": 2.890690690690691e-06,
      "loss": 0.2288,
      "step": 57000
    },
    {
      "epoch": 8.633633633633634,
      "grad_norm": 22.601531982421875,
      "learning_rate": 2.7405405405405404e-06,
      "loss": 0.2466,
      "step": 57500
    },
    {
      "epoch": 8.70870870870871,
      "grad_norm": 0.9369896054267883,
      "learning_rate": 2.5903903903903906e-06,
      "loss": 0.2633,
      "step": 58000
    },
    {
      "epoch": 8.783783783783784,
      "grad_norm": 10.832354545593262,
      "learning_rate": 2.4402402402402404e-06,
      "loss": 0.2297,
      "step": 58500
    },
    {
      "epoch": 8.85885885885886,
      "grad_norm": 7.654428958892822,
      "learning_rate": 2.2903903903903905e-06,
      "loss": 0.2336,
      "step": 59000
    },
    {
      "epoch": 8.933933933933934,
      "grad_norm": 20.344663619995117,
      "learning_rate": 2.1402402402402403e-06,
      "loss": 0.2386,
      "step": 59500
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9175675675675675,
      "eval_f1": 0.9182579564489112,
      "eval_loss": 0.2806470990180969,
      "eval_precision": 0.9133622125958014,
      "eval_recall": 0.9232064668238464,
      "eval_runtime": 6.8833,
      "eval_samples_per_second": 860.047,
      "eval_steps_per_second": 107.506,
      "step": 59940
    },
    {
      "epoch": 9.00900900900901,
      "grad_norm": 8.42081069946289,
      "learning_rate": 1.99009009009009e-06,
      "loss": 0.2485,
      "step": 60000
    },
    {
      "epoch": 9.084084084084084,
      "grad_norm": 25.98297119140625,
      "learning_rate": 1.83993993993994e-06,
      "loss": 0.2313,
      "step": 60500
    },
    {
      "epoch": 9.15915915915916,
      "grad_norm": 19.054916381835938,
      "learning_rate": 1.6900900900900902e-06,
      "loss": 0.2339,
      "step": 61000
    },
    {
      "epoch": 9.234234234234235,
      "grad_norm": 17.01715850830078,
      "learning_rate": 1.53993993993994e-06,
      "loss": 0.2264,
      "step": 61500
    },
    {
      "epoch": 9.30930930930931,
      "grad_norm": 0.13271598517894745,
      "learning_rate": 1.38978978978979e-06,
      "loss": 0.2224,
      "step": 62000
    },
    {
      "epoch": 9.384384384384385,
      "grad_norm": 0.999711275100708,
      "learning_rate": 1.2396396396396398e-06,
      "loss": 0.2321,
      "step": 62500
    },
    {
      "epoch": 9.45945945945946,
      "grad_norm": 13.851149559020996,
      "learning_rate": 1.0897897897897899e-06,
      "loss": 0.2227,
      "step": 63000
    },
    {
      "epoch": 9.534534534534535,
      "grad_norm": 0.29212486743927,
      "learning_rate": 9.396396396396397e-07,
      "loss": 0.2307,
      "step": 63500
    },
    {
      "epoch": 9.60960960960961,
      "grad_norm": 2.285646438598633,
      "learning_rate": 7.894894894894896e-07,
      "loss": 0.2517,
      "step": 64000
    },
    {
      "epoch": 9.684684684684685,
      "grad_norm": 0.19670137763023376,
      "learning_rate": 6.393393393393393e-07,
      "loss": 0.2697,
      "step": 64500
    },
    {
      "epoch": 9.75975975975976,
      "grad_norm": 19.214984893798828,
      "learning_rate": 4.891891891891892e-07,
      "loss": 0.2662,
      "step": 65000
    },
    {
      "epoch": 9.834834834834835,
      "grad_norm": 0.19054338335990906,
      "learning_rate": 3.393393393393394e-07,
      "loss": 0.217,
      "step": 65500
    },
    {
      "epoch": 9.90990990990991,
      "grad_norm": 23.02910804748535,
      "learning_rate": 1.8918918918918921e-07,
      "loss": 0.2481,
      "step": 66000
    },
    {
      "epoch": 9.984984984984985,
      "grad_norm": 0.41014552116394043,
      "learning_rate": 3.903903903903904e-08,
      "loss": 0.2379,
      "step": 66500
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9177364864864865,
      "eval_f1": 0.9184391224250544,
      "eval_loss": 0.2841491401195526,
      "eval_precision": 0.9133910726182545,
      "eval_recall": 0.9235432805658471,
      "eval_runtime": 6.9645,
      "eval_samples_per_second": 850.023,
      "eval_steps_per_second": 106.253,
      "step": 66600
    }
  ],
  "logging_steps": 500,
  "max_steps": 66600,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.4922753261568e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
