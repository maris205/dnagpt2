{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "212e1052-e0d9-404f-a4ee-db199a4c6d17",
   "metadata": {},
   "source": [
    "# 3.2 åºåˆ—ç»“æ„é¢„æµ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb5d83c-8dd6-498b-adc9-1f74c97c3427",
   "metadata": {},
   "source": [
    "è›‹ç™½è´¨çš„ç»“æ„å¯åˆ†ä¸ºå››çº§ï¼š\n",
    "\n",
    "1. ä¸€çº§ç»“æ„ä¹Ÿå°±æ˜¯æ°¨åŸºé…¸åºåˆ—ï¼›\n",
    "2. äºŒçº§ç»“æ„æ˜¯å‘¨æœŸæ€§çš„ç»“æ„æ„è±¡ï¼Œæ¯”å¦‚Î±èºæ—‹Î²æŠ˜å ç­‰\n",
    "3. ä¸‰çº§ç»“æ„æ˜¯æ•´æ¡å¤šè‚½é“¾çš„ä¸‰ç»´ç©ºé—´ç»“æ„\n",
    "4. å››çº§ç»“æ„æ˜¯å‡ ä¸ªè›‹ç™½è´¨åˆ†å­å½¢æˆçš„å¤åˆä½“ç»“æ„ï¼Œæ¯”å¦‚ä¸‰èšä½“ï¼Œå››èš ä½“ç­‰\n",
    "\n",
    "\n",
    "äºŒçº§ç»“æ„ï¼ˆSecondary Structureï¼‰æ˜¯æŒ‡ç”Ÿç‰©å¤§åˆ†å­å¦‚è›‹ç™½è´¨å’Œæ ¸é…¸ï¼ˆRNA å’Œ DNAï¼‰ä¸­å±€éƒ¨çš„ã€æœ‰è§„åˆ™çš„ç©ºé—´æ„è±¡ã€‚è¿™äº›ç»“æ„æ˜¯ç”±åˆ†å­å†…çš„ä¸€äº›åŒ–å­¦é”®æˆ–ç›¸äº’ä½œç”¨ç¨³å®šä¸‹æ¥çš„ï¼Œä½†ä¸æ¶‰åŠæ•´ä¸ªåˆ†å­çš„æ•´ä½“æŠ˜å çŠ¶æ€ã€‚ä»¥ä¸‹æ˜¯å…³äºè›‹ç™½è´¨å’Œ RNA äºŒçº§ç»“æ„çš„ç®€å•ä»‹ç»ï¼š\n",
    "\n",
    "### è›‹ç™½è´¨çš„äºŒçº§ç»“æ„\n",
    "\n",
    "è›‹ç™½è´¨çš„äºŒçº§ç»“æ„ä¸»è¦ç”±ä¸»é“¾åŸå­é—´çš„æ°¢é”®å½¢æˆï¼Œå…·ä½“åŒ…æ‹¬ä»¥ä¸‹å‡ ç§å¸¸è§çš„ç±»å‹ï¼š\n",
    "\n",
    "1. **Î±-èºæ—‹ (Alpha Helix)**\n",
    "   - **æè¿°**ï¼šä¸€ä¸ªå³æ‰‹èºæ—‹ç»“æ„ï¼Œæ¯ä¸ªæ°¨åŸºé…¸æ®‹åŸºæ²¿èºæ—‹è½´æ—‹è½¬çº¦ 100 åº¦ï¼Œå¹¶æ²¿ç€è½´å‘ä¸Šç§»åŠ¨çº¦ 1.5 Ã…ã€‚\n",
    "   - **ç‰¹ç‚¹**ï¼šé€šè¿‡ç›¸é‚»çš„è‚½é”®ä¹‹é—´å½¢æˆçš„æ°¢é”®ç¨³å®šï¼Œé€šå¸¸æ¯ 3.6 ä¸ªæ°¨åŸºé…¸æ®‹åŸºè½¬ä¸€åœˆã€‚\n",
    "\n",
    "2. **Î²-æŠ˜å ç‰‡ (Beta Sheet)**\n",
    "   - **æè¿°**ï¼šç”±å¤šä¸ªå‡ ä¹å¹³è¡Œæˆ–åå¹³è¡Œæ’åˆ—çš„å¤šè‚½é“¾ç»„æˆï¼Œé“¾é—´é€šè¿‡æ°¢é”®è¿æ¥ã€‚\n",
    "   - **ç‰¹ç‚¹**ï¼šå¯ä»¥æ˜¯å¹³è¡Œï¼ˆæ‰€æœ‰é“¾åŒå‘ï¼‰æˆ–åå¹³è¡Œï¼ˆç›¸é‚»é“¾æ–¹å‘ç›¸åï¼‰ï¼Œæä¾›äº†é«˜åº¦åˆšæ€§çš„å¹³é¢ç»“æ„ã€‚\n",
    "\n",
    "3. **è½¬è§’ (Turns)**\n",
    "   - **æè¿°**ï¼šçŸ­çš„åºåˆ—ç‰‡æ®µï¼Œé€šå¸¸åŒ…å« 3 åˆ° 4 ä¸ªæ°¨åŸºé…¸æ®‹åŸºï¼Œç”¨äºæ”¹å˜å¤šè‚½é“¾çš„æ–¹å‘ã€‚\n",
    "   - **ç‰¹ç‚¹**ï¼šæœ€å¸¸è§çš„ç±»å‹æ˜¯ Î²-è½¬è§’ï¼ˆbeta turnï¼‰ï¼Œå®ƒä½¿å¾—é“¾å¯ä»¥åœ¨ç©ºé—´ä¸Šå›æŠ˜ã€‚\n",
    "\n",
    "4. **æ— è§„åˆ™å·æ›² (Random Coil)**\n",
    "   - **æè¿°**ï¼šæ²¡æœ‰å›ºå®šæ¨¡å¼çš„åŒºåŸŸï¼Œå¯èƒ½æ˜¯ç”±äºç¼ºä¹è¶³å¤Ÿçš„æ°¢é”®æˆ–å…¶ä»–ç¨³å®šåŠ›ã€‚\n",
    "   - **ç‰¹ç‚¹**ï¼šè™½ç„¶ç§°ä¸ºâ€œæ— è§„åˆ™â€ï¼Œä½†å®é™…ä¸Šå¯èƒ½åœ¨ç‰¹å®šç¯å¢ƒä¸‹å…·æœ‰åŠŸèƒ½æ€§æ„ä¹‰ã€‚\n",
    "\n",
    "\n",
    "<img src=\"img/protein-structure-1.png\" width=\"500px\" />\n",
    "\n",
    "è›‹ç™½è´¨çš„äºŒçº§ç»“æ„ç»å¸¸ç”¨å›¾å½¢æ¥å½¢è±¡çš„æè¿°ã€‚æ¯”å¦‚ä¸‹å›¾ä¸­é»„è‰²çš„ç®­å¤´ä»£è¡¨å¯¹åº”çš„æ°¨åŸºé…¸ å…·æœ‰Î²æŠ˜ç‰‡ç»“æ„ã€‚æ³¢æµªçº¿ä»£è¡¨èºæ—‹ç»“æ„ï¼Œå°é¼“åŒ…æ˜¯è½¬è§’ã€‚æ­¤å¤–ï¼Œä»¥å­—æ¯å½¢å¼ä¹¦å†™çš„äºŒçº§ç»“æ„åºåˆ—èƒ½å¤Ÿæ›´åŠ ç²¾å‡†çš„æè¿°ã€‚\n",
    "å…¶ä¸­ï¼ŒE ä»£è¡¨Î²æŠ˜å ï¼ŒH ä»£è¡¨Î±èºæ—‹ï¼ŒT ä»£è¡¨è½¬è§’ã€‚æ²¡æœ‰å†™ä»»ä½•å­—æ¯çš„åœ°æ–¹æ˜¯æ¾æ•£çš„ coil ç»“æ„ã€‚å¾ˆå¤šåºåˆ—é¢„æµ‹æ•°æ®é›†ä¸­ï¼Œä¸€èˆ¬ä¸åŒºåˆ†è½¬è§’å’Œcoilç»“æ„ã€‚\n",
    "\n",
    "\n",
    "<img src=\"img/protein-structure-2.png\" width=\"500px\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a583c-f6a5-4a41-8e7e-da27b7e95c50",
   "metadata": {},
   "source": [
    "è·å¾—å®éªŒæµ‹å®šçš„è›‹ç™½è´¨æˆ– RNA çš„äºŒçº§ç»“æ„æ•°æ®ï¼Œé€šå¸¸éœ€è¦ä¾èµ–äºå®éªŒå®¤æŠ€æœ¯å’Œå…¬å…±æ•°æ®åº“ä¸­å·²å‘è¡¨çš„å®éªŒç»“æœã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸ç”¨çš„èµ„æºå’Œæ–¹æ³•ï¼Œå¸®åŠ©ä½ è·å–ç»è¿‡å®éªŒéªŒè¯çš„äºŒçº§ç»“æ„æ•°æ®ï¼š\n",
    "\n",
    "### 1. **è›‹ç™½è´¨äºŒçº§ç»“æ„æ•°æ®**\n",
    "\n",
    "#### a. **PDB (Protein Data Bank)**\n",
    "\n",
    "- **ç½‘å€**ï¼š[RCSB PDB](https://www.rcsb.org/)\n",
    "- **ç‰¹ç‚¹**ï¼šPDB æ˜¯ä¸€ä¸ªå…¨çƒæ€§çš„ç”Ÿç‰©å¤§åˆ†å­ç»“æ„æ•°æ®åº“ï¼ŒåŒ…å«é€šè¿‡ X å°„çº¿æ™¶ä½“å­¦ã€æ ¸ç£å…±æŒ¯ï¼ˆNMRï¼‰å’Œå†·å†»ç”µé•œï¼ˆCryo-EMï¼‰ç­‰å®éªŒæ–¹æ³•æµ‹å®šçš„è›‹ç™½è´¨ä¸‰ç»´ç»“æ„ã€‚\n",
    "- **ä½¿ç”¨æ–¹æ³•**ï¼š\n",
    "  - æœç´¢ç‰¹å®šè›‹ç™½è´¨çš„ PDB ID æˆ–åç§°ã€‚\n",
    "  - æŸ¥çœ‹è¯¦ç»†æ¡ç›®é¡µé¢ï¼Œå…¶ä¸­åŒ…å«äº†è›‹ç™½è´¨çš„ä¸‰çº§ç»“æ„ä¿¡æ¯ï¼Œå¯ä»¥é€šè¿‡å¯è§†åŒ–å·¥å…·å¦‚ PyMOL æˆ– Chimera æ¥è§‚å¯ŸäºŒçº§ç»“æ„å…ƒç´ ï¼ˆå¦‚ Î±-èºæ—‹ã€Î²-æŠ˜å ç‰‡ç­‰ï¼‰ã€‚\n",
    "\n",
    "<img src=\"img/pdb1.png\" width=\"600px\" />\n",
    "\n",
    "From https://www.rcsb.org/sequence/9rsa\n",
    "\n",
    "#### b. **PDBe (Protein Data Bank in Europe)**\n",
    "\n",
    "- **ç½‘å€**ï¼š[PDBe](https://www.ebi.ac.uk/pdbe/)\n",
    "- **ç‰¹ç‚¹**ï¼šPDBe æ˜¯æ¬§æ´²çš„ PDB é•œåƒç«™ç‚¹ï¼Œæä¾›äº†ä¸ RCSB PDB ç±»ä¼¼çš„åŠŸèƒ½ï¼Œå¹¶ä¸”æœ‰é¢å¤–çš„åˆ†æå·¥å…·å’Œæ³¨é‡Šä¿¡æ¯ã€‚\n",
    "- **ä½¿ç”¨æ–¹æ³•**ï¼š\n",
    "  - æœç´¢è›‹ç™½è´¨çš„ PDB ID æˆ–åç§°ã€‚\n",
    "  - ä½¿ç”¨ PDBe-KB å’Œå…¶ä»–å·¥å…·æ¥è·å–è¯¦ç»†çš„ç»“æ„ä¿¡æ¯å’ŒäºŒçº§ç»“æ„æ³¨é‡Šã€‚\n",
    "\n",
    "#### c. **Biomolecule Structure Knowledgebase (BSK)**\n",
    "\n",
    "- **ç½‘å€**ï¼š[BSK](https://bsk.pdbj.org/)\n",
    "- **ç‰¹ç‚¹**ï¼šBSK æ˜¯æ—¥æœ¬çš„ PDB é•œåƒç«™ç‚¹ï¼ŒåŒæ ·æä¾›ä¸°å¯Œçš„ç»“æ„æ•°æ®å’Œåˆ†æå·¥å…·ã€‚\n",
    "- **ä½¿ç”¨æ–¹æ³•**ï¼š\n",
    "  - æœç´¢è›‹ç™½è´¨çš„ PDB ID æˆ–åç§°ã€‚\n",
    "  - æµè§ˆæ¡ç›®ä»¥è·å–è¯¦ç»†çš„ç»“æ„ä¿¡æ¯å’ŒäºŒçº§ç»“æ„æ³¨é‡Šã€‚\n",
    "\n",
    "\n",
    "\n",
    "### 3. **å®éªŒæ–¹æ³•**\n",
    "\n",
    "å¦‚æœä½ éœ€è¦æœ€æ–°çš„æˆ–ç‰¹å®šæ¡ä»¶ä¸‹çš„äºŒçº§ç»“æ„æ•°æ®ï¼Œå¯èƒ½éœ€è¦å‚è€ƒæ–‡çŒ®ä¸­çš„å®éªŒæ–¹æ³•ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„å®éªŒæŠ€æœ¯ï¼š\n",
    "\n",
    "#### a. **X å°„çº¿æ™¶ä½“å­¦**\n",
    "\n",
    "- **åŸç†**ï¼šé€šè¿‡è§£æè›‹ç™½è´¨æˆ– RNA æ™¶ä½“çš„è¡å°„å›¾æ¡ˆæ¥ç¡®å®šå…¶ä¸‰ç»´ç»“æ„ã€‚\n",
    "- **åº”ç”¨**ï¼šé€‚ç”¨äºèƒ½å¤Ÿå½¢æˆç¨³å®šæ™¶ä½“çš„åˆ†å­ã€‚\n",
    "\n",
    "#### b. **æ ¸ç£å…±æŒ¯ï¼ˆNMRï¼‰**\n",
    "\n",
    "- **åŸç†**ï¼šåˆ©ç”¨æ ¸ç£å…±æŒ¯æ³¢è°±æŠ€æœ¯æ¥ç¡®å®šæº¶æ¶²çŠ¶æ€ä¸‹åˆ†å­çš„ç»“æ„ã€‚\n",
    "- **åº”ç”¨**ï¼šé€‚ç”¨äºè¾ƒå°çš„è›‹ç™½è´¨å’Œ RNA åˆ†å­ã€‚\n",
    "\n",
    "#### c. **å†·å†»ç”µé•œï¼ˆCryo-EMï¼‰**\n",
    "\n",
    "- **åŸç†**ï¼šé€šè¿‡ä½æ¸©å†·å†»æ ·å“å¹¶åœ¨ç”µå­æ˜¾å¾®é•œä¸‹æˆåƒæ¥ç¡®å®šåˆ†å­ç»“æ„ã€‚\n",
    "- **åº”ç”¨**ï¼šé€‚ç”¨äºè¾ƒå¤§çš„å¤åˆç‰©å’Œéš¾ä»¥ç»“æ™¶çš„åˆ†å­ã€‚\n",
    "\n",
    "\n",
    "\n",
    "### 4. **æ–‡çŒ®æ£€ç´¢**\n",
    "\n",
    "#### a. **PubMed**\n",
    "\n",
    "- **ç½‘å€**ï¼š[PubMed](https://pubmed.ncbi.nlm.nih.gov/)\n",
    "- **ç‰¹ç‚¹**ï¼šPubMed æ˜¯ä¸€ä¸ªå¹¿æ³›ä½¿ç”¨çš„ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®æ•°æ®åº“ï¼Œæä¾›äº†å¤§é‡å…³äºè›‹ç™½è´¨å’Œ RNA åŠŸèƒ½åŠç»“æ„çš„ç ”ç©¶è®ºæ–‡ã€‚\n",
    "- **ä½¿ç”¨æ–¹æ³•**ï¼š\n",
    "  - ä½¿ç”¨å…³é”®è¯æœç´¢ä¸ç‰¹å®šè›‹ç™½è´¨æˆ– RNA ç›¸å…³çš„å®éªŒç ”ç©¶ã€‚\n",
    "  - é˜…è¯»è®ºæ–‡ä»¥è·å–è¯¦ç»†çš„å®éªŒæ•°æ®å’ŒäºŒçº§ç»“æ„æè¿°ã€‚\n",
    "\n",
    "### æ€»ç»“\n",
    "\n",
    "è·å¾—å®éªŒæµ‹å®šçš„è›‹ç™½è´¨æˆ– RNA çš„äºŒçº§ç»“æ„æ•°æ®ä¸»è¦ä¾èµ–äºå…¬å…±æ•°æ®åº“å¦‚ PDB å’Œ NDBï¼Œè¿™äº›æ•°æ®åº“æ”¶å½•äº†é€šè¿‡å¤šç§å®éªŒæ–¹æ³•æµ‹å®šçš„ç»“æ„ä¿¡æ¯ã€‚æ­¤å¤–ï¼ŒæŸ¥é˜…ç›¸å…³æ–‡çŒ®ä¹Ÿæ˜¯ä¸€ç§é‡è¦çš„é€”å¾„ï¼Œå¯ä»¥æ‰¾åˆ°æœ€æ–°çš„æˆ–ç‰¹å®šæ¡ä»¶ä¸‹çš„å®éªŒç»“æœã€‚å¯¹äºå…·ä½“çš„å®éªŒæ–¹æ³•ï¼Œå¦‚ X å°„çº¿æ™¶ä½“å­¦ã€NMR å’Œ Cryo-EM ç­‰ï¼Œå®ƒä»¬å„è‡ªæœ‰é€‚ç”¨çš„åœºæ™¯å’Œä¼˜åŠ¿ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cadfd11-2130-429d-848f-39371356ca10",
   "metadata": {},
   "source": [
    "## æ•´ç†å¥½çš„æ•°æ®\n",
    "\n",
    "https://huggingface.co/datasets/proteinea/secondary_structure_prediction\n",
    "\n",
    "<img src=\"img/ds_structure.png\" width=\"600px\" />\n",
    "\n",
    "https://huggingface.co/datasets/genbio-ai/rna-secondary-structure-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "134a72e3-597a-446e-9193-d060a6e677f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport os\\n\\n# è®¾ç½®ç¯å¢ƒå˜é‡, autodlä¸“åŒº å…¶ä»–idc\\nos.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\\n\\n# æ‰“å°ç¯å¢ƒå˜é‡ä»¥ç¡®è®¤è®¾ç½®æˆåŠŸ\\nprint(os.environ.get('HF_ENDPOINT'))\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "# è®¾ç½®ç¯å¢ƒå˜é‡, autodlä¸€èˆ¬åŒºåŸŸ\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "# è®¾ç½®ç¯å¢ƒå˜é‡, autodlä¸“åŒº å…¶ä»–idc\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "# æ‰“å°ç¯å¢ƒå˜é‡ä»¥ç¡®è®¤è®¾ç½®æˆåŠŸ\n",
    "print(os.environ.get('HF_ENDPOINT'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b43dd5f2-6b23-4b51-ad04-7b7ded732cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, TrainingArguments, Trainer\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import GPT2LMHeadModel, AutoConfig,GPT2Tokenizer\n",
    "from transformers import AutoModelForTokenClassification \n",
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c66fa5b-b8b8-4dfd-ada1-32ed9e690c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set tokenizer,dna protein \n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"dnagpt/gene_eng_gpt2_v0\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70a3fd79-48bf-4452-a7ee-689f1b11e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# 1. load ~11k samples from promoters prediction dataset\n",
    "dataset = load_dataset(\"proteinea/secondary_structure_prediction\")['train'].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13cd141e-98c3-47da-8e21-cba5576707fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'dssp3', 'dssp8', 'disorder', 'cb513_mask'],\n",
       "        num_rows: 9712\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'dssp3', 'dssp8', 'disorder', 'cb513_mask'],\n",
       "        num_rows: 1080\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7936af74-3f5f-43c1-aa69-fd7b08989e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'MTQTQPVTPTPPASFQTQHDPRTRLGATPLPGGAGTRFRLWTSTARTVAVRVNGTEHVMTSLGGGIYELELPVGPGARYLFVLDGVPTPDPYARFLPDGVHGEAEVVDFGTFDWTDADWHGIKLADCVFYEVHVGTFTPEGTYRAAAEKLPYLKELGVTAIQVMPLAAFDGQRGWGYDGAAFYAPYAPYGRPEDLMALVDAAHRLGLGVFLDVVYNHFGPSGNYLSSYAPSYFTDRFSSAWGMGLDYAEPHMRRYVTGNARMWLRDYHFDGLRLDATPYMTDDSETHILTELAQEIHELGGTHLLLAEDHRNLPDLVTVNHLDGIWTDDFHHETRVTLTGEQEGYYAGYRGGAEALAYTIRRGWRYEGQFWAVKGEEHERGHPSDALEAPNFVYCIQNHDQIGNRPLGERLHQSDGVTLHEYRGAAALLLTLPMTPLLFQGQEWAASTPFQFFSDHAGELGQAVSEGRKKEFGGFSGFSGEDVPDPQAEQTFLNSKLNWAEREGGEHARTLRLYRDLLRLRREDPVLHNRQRENLTTGHDGDVLWVRTVTGAGERVLLWNLGQDTRAVAEVKLPFTVPRRLLLHTEGREDLTLGAGEAVLVG',\n",
       " 'dssp3': 'CCCCCCCCCCCCCCCCCCCCHHHCCEEEECHHHCCEEEEEECCCCCCEEEEECCEEEECEEEECCEEEEEECCCCCCEEEEEECCEEECCCCCCCCCCCCCCCEECCCCCCCCCCCCCCCCCCHHHCCEEEECHHHHCCCCCHHHHHHCHHHHHHHCCCEEEECCCEECCCCCCCCCCCCEEEEECHHHCCHHHHHHHHHHHHHCCCEEEEEECCCCCCCCCCCHHHHCHHHEEEEEECCCCEEECCCCHHHHHHHHHHHHHHHHHHCCCEEEECCHHHCCCCCCCCHHHHHHHHHHCCCCCCEEEEECCCCCCHHHHCCCCCEEECCHHHHHHHHHHHCCCCHHHHHCCCCHHHHHHHHHHCCCCEEEEECCCCCCEEEECCCCCCCHHHEEEECCCHHHHHCCCCCCCHHHCCCCCHHHHHHHHHHHHHCCCEEEEECCHHHCCCCCCCCCCCCCHHHHHHHHHHHHHHCCCCCCCCCCCCCCCCCHHHHHCCCCCCHHHHCHHHHHHHHHHHHHHHHHHHCCCCCCCCHHHEEEEEECCEEEEEEEECCEEEEEEEECCCCCEEHHHCCCCCCCCCCEEEECCCCCCCEECCCCEEEEC',\n",
       " 'dssp8': 'CCCCCCCCCCCCCCCCCSCCGGGCSEEEECGGGCCEEEEEECSSCSSEEEEETTEEEECEEEETTEEEEEESCCTTCEEEEEETTEEECCTTCSCCTTCTTSCEECCCTTSSCCCCTTCCCCCGGGCCEEEECHHHHSSSCSHHHHHHTHHHHHHHTCCEEEECCCEECSSSCCCSTTCCEEEEECGGGCCHHHHHHHHHHHHHTTCEEEEEECCSCCCSSSCCHHHHCGGGEEEEEECSSSEEECTTSHHHHHHHHHHHHIIIIIHCCSEEEETTGGGCCCCSSSCHHHHHHHHHHTTCSCCEEEEECSSCCTHHHHTTCCSEEECTHHHHHHHHHHHCCCSGGGGGCCCSHHHHHHHHHHSSSCEEEEECCTTCCEEEECCCTTCCGGGEEEESCCHHHHHTSTTCCCGGGSTTCCHHHHHHHHHHHHHSSSEEEEETTGGGTCSSCCCCCCCCCHHHHHHHHHHHHHHCCCCCCCCCCCCCCTTSHHHHHTTSCCSGGGGSHHHHHHHHHHHHHHHHHHHCTTTTCCCGGGEEEEEETTEEEEEEEETTEEEEEEEECSSSCEEGGGSCCSSCCCCCEEEETTCCSSSEECTTCEEEEC',\n",
       " 'disorder': '0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0',\n",
       " 'cb513_mask': '1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47b1ac0c-e934-4ac3-b869-509515b15aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna datasets  mean token lenght 96.07685185185186 min token length 7 max token length 576\n"
     ]
    }
   ],
   "source": [
    "token_len_list = []\n",
    "for item in dataset[\"test\"]:\n",
    "    inputs = tokenizer.tokenize(item[\"input\"])\n",
    "    token_len_list.append( len(inputs) )\n",
    "\n",
    "mean_len = sum(token_len_list)/len(token_len_list)\n",
    "min_len  = min(token_len_list)\n",
    "max_len = max(token_len_list)\n",
    "\n",
    "print(\"dna datasets \", \"mean token lenght\", mean_len, \"min token length\", min_len, \"max token length\", max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b32de6e-fe08-426e-983e-7dd157c9af62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels: 3\n",
      "Label to ID mapping: {'C': 0, 'H': 1, 'E': 2, '<pad>': 3}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Confirm the number of labels and create a mapping from string labels to integer IDs.\n",
    "all_labels = [label for item in dataset[\"train\"] for label in item[\"dssp3\"]]\n",
    "label_counts = Counter(all_labels)\n",
    "num_labels = len(label_counts)\n",
    "\n",
    "# Define a special ID for padding. Make sure this ID is not used by any actual label.\n",
    "# If you have 3 classes, start with 3 or higher.\n",
    "pad_token_label_id = num_labels  # Assuming no other labels have this ID.\n",
    "\n",
    "label_to_id = {label: i for i, (label, _) in enumerate(label_counts.items())}\n",
    "label_to_id['<pad>'] = pad_token_label_id  # Add padding token to the mapping.\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "\n",
    "print(f\"Number of unique labels: {num_labels}\")\n",
    "print(\"Label to ID mapping:\", label_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bd65f47-3325-4357-a896-9a0abf160e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForTokenClassification were not initialized from the model checkpoint at dnagpt/gene_eng_gpt2_v0 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#set model\n",
    "#model = AutoModelForTokenClassification.from_pretrained('dnagpt/gene_eng_gpt2_v0', )\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    'dnagpt/gene_eng_gpt2_v0',\n",
    "    num_labels=num_labels + 1,  # Include the padding label in the count.\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e247ac1e-bcd4-4aaf-9f91-dc939e5abe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Preprocess the data\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import torch\n",
    "# Define the maximum sequence length based on your model or dataset requirements.\n",
    "max_seq_length = 128  # Adjust this value as needed.\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"input\"], \n",
    "        truncation=True, \n",
    "        padding='max_length', \n",
    "        max_length=max_seq_length,\n",
    "        return_tensors=\"pt\"  # Return PyTorch tensors directly.\n",
    "    )\n",
    "    \n",
    "    labels = []\n",
    "    for label in examples['dssp3']:\n",
    "        label_ids = [label_to_id[l] if l in label_to_id else pad_token_label_id for l in label]\n",
    "        # Ensure labels are padded/truncated to the same length as inputs.\n",
    "        if len(label_ids) > max_seq_length:\n",
    "            label_ids = label_ids[:max_seq_length]\n",
    "        else:\n",
    "            label_ids = label_ids + [pad_token_label_id] * (max_seq_length - len(label_ids))\n",
    "        \n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = torch.tensor(labels)\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8144d093-e8d3-41ff-ae4f-82aa1f28d689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707978d4f8304cada1041f8e794d79b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab7ae3ed05244bab1fe13050aad3764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de5067da-a010-4e0d-b99b-659ee2d3cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that are not required by the model.\n",
    "columns_to_remove = ['input', 'dssp3', 'dssp8', 'disorder', 'cb513_mask']\n",
    "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"], output_all_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fcce6f4e-9716-4fe4-9250-e201a442bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data collator for handling padding during batching.\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, pad_to_multiple_of=8, label_pad_token_id=pad_token_label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa3e62b3-dba4-4cef-9bb7-de410f4bb444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1443/204012889.py:41: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# 6. Prepare training\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "        predictions, labels = p\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Remove ignored index (special tokens)\n",
    "        true_predictions = [\n",
    "            [id_to_label[p] for (p, l) in zip(prediction, label) if l != pad_token_label_id]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        true_labels = [\n",
    "            [id_to_label[l] for (p, l) in zip(prediction, label) if l != pad_token_label_id]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "\n",
    "        results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "        return {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }\n",
    "    \n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type=\"constant_with_warmup\",\n",
    "    optim='adamw_torch',\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a76f326-1097-47bb-bb9d-03b77c4f8f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8001' max='12140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8001/12140 09:41 < 05:00, 13.76 it/s, Epoch 13.18/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.102200</td>\n",
       "      <td>0.923186</td>\n",
       "      <td>0.314843</td>\n",
       "      <td>0.125521</td>\n",
       "      <td>0.179485</td>\n",
       "      <td>0.503214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.942100</td>\n",
       "      <td>0.883362</td>\n",
       "      <td>0.357413</td>\n",
       "      <td>0.153466</td>\n",
       "      <td>0.214731</td>\n",
       "      <td>0.521366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.898500</td>\n",
       "      <td>0.895442</td>\n",
       "      <td>0.355443</td>\n",
       "      <td>0.194234</td>\n",
       "      <td>0.251199</td>\n",
       "      <td>0.522545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.870200</td>\n",
       "      <td>0.891230</td>\n",
       "      <td>0.367170</td>\n",
       "      <td>0.050731</td>\n",
       "      <td>0.089145</td>\n",
       "      <td>0.526761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.831900</td>\n",
       "      <td>0.890030</td>\n",
       "      <td>0.373252</td>\n",
       "      <td>0.197096</td>\n",
       "      <td>0.257971</td>\n",
       "      <td>0.530358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.815800</td>\n",
       "      <td>0.867876</td>\n",
       "      <td>0.378696</td>\n",
       "      <td>0.236628</td>\n",
       "      <td>0.291262</td>\n",
       "      <td>0.540153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.873521</td>\n",
       "      <td>0.380925</td>\n",
       "      <td>0.212640</td>\n",
       "      <td>0.272927</td>\n",
       "      <td>0.544393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.785100</td>\n",
       "      <td>0.872138</td>\n",
       "      <td>0.385372</td>\n",
       "      <td>0.156363</td>\n",
       "      <td>0.222462</td>\n",
       "      <td>0.547684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.774100</td>\n",
       "      <td>0.885855</td>\n",
       "      <td>0.384813</td>\n",
       "      <td>0.180280</td>\n",
       "      <td>0.245531</td>\n",
       "      <td>0.549681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.750800</td>\n",
       "      <td>0.884582</td>\n",
       "      <td>0.388464</td>\n",
       "      <td>0.206529</td>\n",
       "      <td>0.269681</td>\n",
       "      <td>0.555933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.886323</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>0.202713</td>\n",
       "      <td>0.268369</td>\n",
       "      <td>0.557624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.731000</td>\n",
       "      <td>0.878285</td>\n",
       "      <td>0.365956</td>\n",
       "      <td>0.315728</td>\n",
       "      <td>0.338991</td>\n",
       "      <td>0.555857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.708900</td>\n",
       "      <td>0.912278</td>\n",
       "      <td>0.377030</td>\n",
       "      <td>0.249346</td>\n",
       "      <td>0.300174</td>\n",
       "      <td>0.555030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: H seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: H seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: H seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: H seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: H seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: H seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: H seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: H seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: H seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: H seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: H seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: H seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: H seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/root/miniconda3/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:595] . unexpected pos 1216226560 vs 1216226452",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/serialization.py:628\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 628\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/serialization.py:862\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    861\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 862\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:764] . PytorchStreamWriter failed writing file data/94: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:2164\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2165\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2169\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:2591\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2589\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2590\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2591\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\n\u001b[1;32m   2593\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2594\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2595\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:3056\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[1;32m   3053\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save \u001b[38;5;241m=\u001b[39m is_new_best_metric\n\u001b[1;32m   3055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3057\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:3192\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial)\u001b[0m\n\u001b[1;32m   3188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(output_dir, _internal_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   3191\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[0;32m-> 3192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_optimizer_and_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3193\u001b[0m     \u001b[38;5;66;03m# Save RNG state\u001b[39;00m\n\u001b[1;32m   3194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_rng_state(output_dir)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:3313\u001b[0m, in \u001b[0;36mTrainer._save_optimizer_and_scheduler\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   3308\u001b[0m     save_fsdp_optimizer(\n\u001b[1;32m   3309\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfsdp_plugin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, output_dir\n\u001b[1;32m   3310\u001b[0m     )\n\u001b[1;32m   3311\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   3312\u001b[0m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[0;32m-> 3313\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3315\u001b[0m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[1;32m   3316\u001b[0m is_deepspeed_custom_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   3317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[1;32m   3318\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/serialization.py:627\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    624\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/serialization.py:475\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:595] . unexpected pos 1216226560 vs 1216226452"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "950c460f-5631-4c9a-819b-1e3ac484cc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9122781157493591,\n",
       " 'eval_precision': 0.3770299145299145,\n",
       " 'eval_recall': 0.2493464283190843,\n",
       " 'eval_f1': 0.3001743716242079,\n",
       " 'eval_accuracy': 0.5550300748427384}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8174c1c6-a5bc-4fe3-8f9b-356625531e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 2.49\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a22f131-9e5f-4125-942a-22d1b1e6373b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./secondary_structure_model/tokenizer_config.json',\n",
       " './secondary_structure_model/special_tokens_map.json',\n",
       " './secondary_structure_model/vocab.json',\n",
       " './secondary_structure_model/merges.txt',\n",
       " './secondary_structure_model/added_tokens.json')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä¿å­˜æ¨¡å‹\n",
    "model.save_pretrained(\"./secondary_structure_model\")\n",
    "tokenizer.save_pretrained(\"./secondary_structure_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5817a6c-c707-4005-9210-2a12ff0d43b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æ¨¡å‹\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"./secondary_structure_model\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"./secondary_structure_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f6ebdc6-8ff8-4947-ada4-05ff4b28e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿›è¡Œé¢„æµ‹\n",
    "def predict_secondary_structure(sequence):\n",
    "    inputs = tokenizer(sequence, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    predictions = outputs.logits.argmax(dim=-1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "841ebba8-7619-411f-a11e-841de3a3f064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 2, 2, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "# ç¤ºä¾‹é¢„æµ‹\n",
    "sequence = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "predictions = predict_secondary_structure(sequence)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e7d22e-0545-422b-b8ba-7990ca127d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
